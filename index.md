## EDUCATION
**<span style="float:left">Beihang University</span>** *<span style="float:right">September 2020 - Present</span>*
<br>Master Student, Advisor: Xianglong Liu

**<span style="float:left">Shandong University</span>** *<span style="float:right">September 2016 - June 2020</span>*
<br>Bachelor of Engineering in Computer Science and Technology (Honor Class)
## PUBLICATION
**Xiuying Wei***, Ruihao Gong*, Yuhang Li, Xianglong Liu, and Fengwei Yu. QDrop: Randomly Dropping Quantization for Extremely Low-bit Post-Training Quantization. In International Conference on Learning Representations, **ICLR 2022**.
## RESEARCH EXPERIENCE
**<span style="float:left">Research on pratical post-training quantization and application</span>** *<span style="float:right">November 2021 - Present</span>*<br>
Research Intern, SenseTime Group Limited<br>
Advisor: [Ruihao Gong](https://xhplus.github.io/)
- In charge of post-training quantization part (popular algorithm integration, accuracy comparison and document writing) for the framework of [MQBench](https://mqbench.readthedocs.io/en/latest/), a reproducible and deployable quantization benchmark.
- Devote to novel and pratical quantization techniques in the field of natural language processing.

**<span style="float:left">Explore the limit of post-training quantization</span>** *<span style="float:right">March 2021 - October 2021</span>*<br>
Student in State Key Lab of Software Development Environment<br>
Advisor: Professor [Xianglong Liu](https://xlliu-beihang.github.io/)
- Studied post-training quantization, which only uses few images and limited resources to convert cumbersome full precision networks into low-bit integer quantization networks.
- Conducted a research from quantization optimization procedure perspective and builded a theoretical framework between flatness and quantization.
- Proposed a simple yet effective method dubbed as QDrop and established a new state of the artespecially at ultra low-bit by randomly dropping activation quantization during calibration. 
- First author of the proposed algorithm, which is published at ICLR 2022 as a conference paper and has been **rated 8886 by the reviewers**.
## AWARDS
<span style="float:left">SenseTime Future Star Award</span> *<span style="float:right">2021</span>* <br>
<span style="float:left">Silver Medal of 44th ACM-ICPC Asia-East Continent Final</span> *<span style="float:right">2019</span>* <br>
<span style="float:left">Gold Medal of 5th China Collegiate Programming Contest</span> *<span style="float:right">2019</span>* <br>
<span style="float:left">Silver Medal of 43rd ACM-ICPC Asia-East Continent Final</span> *<span style="float:right">2018</span>* <br>
<span style="float:left">Gold Medal of 43rd ACM-ICPC Asia Regional Contest (Qingdao Site)</span> *<span style="float:right">2018</span>* <br>
<span style="float:left">Gold Medal of 43rd ACM-ICPC Asia Regional Contest (Nanjing Site)</span> *<span style="float:right">2018</span>* <br>
<span style="float:left">Silver Medal of 4th China Collegiate Programming Contest</span> *<span style="float:right">2018</span>* <br>

